{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import clip\n",
    "from typing import List, Optional\n",
    "import torch\n",
    "from lavis.models import load_model_and_preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Faiss: \n",
    "    def __init__(self, database_path: str, use_gpu: bool = True) -> None:\n",
    "        database = np.load(database_path)\n",
    "        \n",
    "        db_size,_, dim = database.shape\n",
    "        \n",
    "        print('Indexing database...')\n",
    "        print('database shape:', database.shape)\n",
    "        # self.index_flat = self._get_indexer(dim, 'IP')\n",
    "        self.index_flat = faiss.read_index(database_path)\n",
    "\n",
    "\n",
    "        if use_gpu:\n",
    "            res = faiss.StandardGpuResources()  # use a single GPU\n",
    "\n",
    "            # make it into a gpu index\n",
    "            self.index_flat = faiss.index_cpu_to_gpu(res, 0, self.index_flat)\n",
    "\n",
    "        self.index_flat.add(database)\n",
    "\n",
    "\n",
    "        print('Finish indexing database')\n",
    "        \n",
    "    def _get_indexer(self, dim: int, id_type: str):\n",
    "        # if id_type == 'L2':\n",
    "        #     return faiss.IndexFlatL2(dim)\n",
    "\n",
    "        return faiss.read_index(\"/mmlabworkspace/Students/AIC/MMLAB-UIT-AIC2023/faiss/info.json\")\n",
    "    \n",
    "    def search(self, encoded_queries: np.array, top_k: int) -> np.array:\n",
    "        \"\"\"_Return indexes of every query in queries\n",
    "\n",
    "        Args:\n",
    "            queries (np.array): (n_queries, dim)\n",
    "            top_k (int): top k nearest\n",
    "\n",
    "        Returns:\n",
    "            np.array: (n_queries, top_k)\n",
    "        \"\"\"\n",
    "        print('query.shape:', encoded_queries.shape)\n",
    "        \n",
    "        distances, indices = self.index_flat.search(encoded_queries, top_k)\n",
    "        return distances, indices\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, model_name: str='ViT-B/16',project=None, use_gpu: bool = True) -> None:\n",
    "        if use_gpu:\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "        self.model_name = model_name\n",
    "        self.project = project\n",
    "        print('Loading model...')\n",
    "        if self.model_name == 'BLIP':\n",
    "            self.model, self.preprocess, self.tokenize = load_model_and_preprocess(\n",
    "                                                        name=\"blip2_feature_extractor\",\n",
    "                                                        model_type=\"pretrain\",\n",
    "                                                        is_eval=True,\n",
    "                                                        device=self.device)\n",
    "        else:\n",
    "            self.tokenize = clip.tokenize\n",
    "            self.model, self.preprocess = clip.load(model_name, device=self.device)\n",
    "\n",
    "        print('Finish loading model.')\n",
    "            \n",
    "    def encode_texts(self, text: List[str]) -> np.array:\n",
    "        \n",
    "                \n",
    "        if self.model_name == 'BLIP':\n",
    "            text_input = self.tokenize[\"eval\"](text[0])\n",
    "            sample = {\"image\": \"\", \"text_input\": [text_input]}\n",
    "            features_text = self.model.extract_features(sample, mode=\"text\")\n",
    "            if self.project:\n",
    "                text_features = features_text.text_embeds_proj[:,0,:].t().cpu().numpy().astype(np.float32)\n",
    "            else:\n",
    "                text_features = features_text.text_embeds[:,0,:].t().cpu().numpy().astype(np.float32)\n",
    "        else:\n",
    "            tokenized_text = self.tokenize(text).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                text_features = self.model.encode_text(tokenized_text)\n",
    "                text_features = text_features.cpu().numpy()\n",
    "                text_features = text_features / np.linalg.norm(text_features)\n",
    "        return text_features\n",
    "            \n",
    "    def encode_image(self, image) -> np.array:\n",
    "        if self.model_name == 'ViT_B/16':\n",
    "            image = self.preprocess(image).unsqueeze(0).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                image_feature = self.model.encode(image)\n",
    "        # if self.model_name == 'BLIP':\n",
    "        #     from PIL import Image\n",
    "        #     image = Image.fromarray(cv2.imread(img_file))\n",
    "        #     image = vis_processors[\"eval\"](image).unsqueeze(0).cuda()\n",
    "        #     sample = {\"image\": image, \"text_input\": [\"\"]}\n",
    "        #     feature_image = model.extract_features(sample, mode=\"image\")\n",
    "        #     if self.project:\n",
    "        #         text_features = features_text.image_embeds_proj\n",
    "        #         print('project=True:', text_features.shape)\n",
    "        #     else:\n",
    "        #         text_features = features_text.image_embeds\n",
    "        #         print('project=False:', text_features.shape)\n",
    "        return image_feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database shape (202148, 32, 256)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Testing\n",
    "\n",
    "database = np.load('/mmlabworkspace/Students/AIC/MMLAB-UIT-AIC2023/data/Merge/Feature_data/BLIP_256/feature.npy')\n",
    "print('Database shape', database.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing database...\n",
      "database shape: (202148, 32, 256)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error in faiss::Index* faiss::read_index(faiss::IOReader*, int) at /home/circleci/miniconda/conda-bld/faiss-pkg_1681998300314/work/faiss/impl/index_read.cpp:1027: Index type 0x4d554e93 (\"\\x93NUM\") not recognized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_212/1100829573.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdatabase_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/mmlabworkspace/Students/AIC/MMLAB-UIT-AIC2023/data/Merge/Feature_data/BLIP_256/feature.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfaiss_searcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFaiss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatabase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Index time:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_212/2139042656.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, database_path, use_gpu)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Indexing database...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'database shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# self.index_flat = self._get_indexer(dim, 'IP')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/faiss/swigfaiss_avx2.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m  11711\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11712\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_swigfaiss_avx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Error in faiss::Index* faiss::read_index(faiss::IOReader*, int) at /home/circleci/miniconda/conda-bld/faiss-pkg_1681998300314/work/faiss/impl/index_read.cpp:1027: Index type 0x4d554e93 (\"\\x93NUM\") not recognized"
     ]
    }
   ],
   "source": [
    "database_path = '/mmlabworkspace/Students/AIC/MMLAB-UIT-AIC2023/data/Merge/Feature_data/BLIP_256/feature.npy'\n",
    "start_time = time.time()\n",
    "faiss_searcher = Faiss(database_path=database_path)\n",
    "print('Index time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "encoder = Encoder(model_name=\"BLIP\", project=True)\n",
    "print('Load model time:', time.time() - start_time)\n",
    "start_time = time.time()\n",
    "queries = np.array(['A big cat'])\n",
    "encoded_text = encoder.encode_texts(queries)\n",
    "print('Encode time:', time.time() - start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "result_indices = faiss_searcher.search(encoded_text, top_k=10).ravel()\n",
    "print('Search time:', time.time() - start_time)\n",
    "print(result_indices[0])\n",
    "\n",
    "# with open('data/keyframe_names') as f:\n",
    "#     keyframe_names = json.load(f)\n",
    "# result = [keyframe_names[i] for i in result_indices]\n",
    "# print(result)\n",
    "\n",
    "# for file in glob.glob('faiss/result/*'):\n",
    "#     os.remove(file)\n",
    "# os.makedirs('faiss/result/', exist_ok=True)\n",
    "# for image_file in result:\n",
    "#     img = Image.open(image_file)\n",
    "#     img.save(os.path.join('faiss/result', os.path.basename(image_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from unittest.result import failfast\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import info\n",
    "\n",
    "\n",
    "def load_embeddings(embeddings_dir):\n",
    "    if os.path.exists(f'{embeddings_dir}/embeddings.pkl'):\n",
    "        with open(f'{embeddings_dir}/embeddings.pkl', 'rb') as f:\n",
    "            embeddings = pickle.load(f)\n",
    "    else:\n",
    "        embeddings = []\n",
    "        for embedding_file in tqdm(sorted(glob.glob(f\"{embeddings_dir}/*.npz\"))):\n",
    "            data = np.load(embedding_file)\n",
    "            embeddings.append(np.array(data.get(\"feature_lst\")[:, 0, 0, :]).astype(np.float32))\n",
    "        embeddings = np.vstack(embeddings)\n",
    "        \n",
    "        with open(f'{embeddings_dir}/embeddings.pkl', 'wb') as f:\n",
    "            pickle.dump(embeddings, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    print(f\"Loaded embedding with shape: {embeddings.shape}\")\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def set_nprobe(index, nprobe):\n",
    "    changed = False\n",
    "    if hasattr(index, \"nprobe\") and nprobe and index.nprobe != nprobe:\n",
    "        index.nprobe = nprobe\n",
    "        print(f\"Set nprobe = {nprobe}\")\n",
    "        changed = True\n",
    "    return changed\n",
    "\n",
    "\n",
    "def auto_nprobe(nlist):\n",
    "    nprobe = min(max(round(2e-3 * nlist), 128), nlist)\n",
    "    print(f\"Automatic nprobe: {nprobe}\")\n",
    "    return nprobe\n",
    "\n",
    "\n",
    "def auto_ivf_sq(nembeddings):\n",
    "    # refering to https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index\n",
    "    ncentroids = 0\n",
    "    if nembeddings <= 1e6:\n",
    "        ncentroids = int(np.ceil(16 * np.sqrt(nembeddings)))\n",
    "    elif 1e6 < nembeddings <= 10e6:\n",
    "        ncentroids = 65536\n",
    "    elif 10e6 < nembeddings <= 100e6:\n",
    "        ncentroids = 262144\n",
    "    elif 100e6 <= nembeddings <= 1e9:\n",
    "        ncentroids = 1048576\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Too many embeddings! Please set the index factory string yourself\"\n",
    "        )\n",
    "\n",
    "    ncentroids = min(nembeddings // 39, ncentroids)\n",
    "    index_factory_string = f\"IVF{ncentroids},SQ4\"\n",
    "    print(f\"Automatic index factory string: {index_factory_string}\")\n",
    "    return index_factory_string\n",
    "\n",
    "\n",
    "def run(\n",
    "    embeddings_dir,\n",
    "    output_dir,\n",
    "    index_factory_string=None,\n",
    "    distance=\"IP\",\n",
    "    nprobe=None,\n",
    "    use_gpu=False,\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"AIC_db_{distance}.index\")\n",
    "    if not os.path.exists(output_path):\n",
    "        use_gpu = use_gpu and torch.cuda.is_available()\n",
    "        embeddings = load_embeddings(embeddings_dir)\n",
    "        ndim = embeddings.shape[1]\n",
    "        if len(embeddings) > 1e7:\n",
    "            print(\"WARNING: #embeddings > 10M, please use GPU(s) for saving time!!!\")\n",
    "\n",
    "        if index_factory_string is None:\n",
    "            index_factory_string = auto_ivf_sq(len(embeddings))\n",
    "        if distance == \"IP\":\n",
    "            distance = faiss.METRIC_INNER_PRODUCT\n",
    "        elif distance == \"L2\":\n",
    "            distance = faiss.METRIC_L2\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        index = faiss.index_factory(ndim, index_factory_string, distance)\n",
    "\n",
    "        if use_gpu:\n",
    "            ngpus = faiss.get_num_gpus()\n",
    "            print(f\"Using {ngpus} gpus\")\n",
    "            index = faiss.index_cpu_to_all_gpus(index)\n",
    "        else:\n",
    "            print(\"Using cpu\")\n",
    "\n",
    "        index.train(embeddings)\n",
    "        index.add(embeddings)\n",
    "        if use_gpu:\n",
    "            index = faiss.index_gpu_to_cpu(index)\n",
    "\n",
    "        if nprobe is None and index.nlist:\n",
    "            nprobe = auto_nprobe(index.nlist)\n",
    "        set_nprobe(index, nprobe)\n",
    "        faiss.write_index(index, output_path)\n",
    "    else:\n",
    "        print(\"Found existing index\")\n",
    "        index = faiss.read_index(output_path)\n",
    "        if set_nprobe(index, nprobe):\n",
    "            faiss.write_index(index, output_path)\n",
    "\n",
    "    info.run(output_dir, output_dir)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--embeddings_dir\")\n",
    "    parser.add_argument(\"--output_dir\")\n",
    "    parser.add_argument(\n",
    "        \"--index_factory_string\",\n",
    "        default=None,\n",
    "        help=\"By default, it will use IVFSQ index\",\n",
    "    )\n",
    "    parser.add_argument(\"--distance\", default=\"IP\", choices=[\"L2\", \"IP\"])\n",
    "    parser.add_argument(\n",
    "        \"--nprobe\",\n",
    "        type=int,\n",
    "        default=None,\n",
    "        help=\"How many clusters you want to dive in for each search. By default it will be 2e-3 * nlist\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_gpu\", action=\"store_true\", help=\"Please use GPU(s) if #embeddings >= 10M\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    run(**vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce827457a4ed7326deea6ee7ca32776ee947010b881dc859b3b084d6bae76f9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
